{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_5Z3FbplQ-ml"
      },
      "source": [
        "#Disclaimer to the user\n",
        " the prompt travel generation doesn't work in certain colab server locations, so please disconnect, and reconnect the runtime to change the runtime location.\n",
        "\n",
        " you can check the server location using the command: !curl ipinfo.io\n",
        "\n",
        " Please check locations in the below link https://developers.generativeai.google/available_regions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U2hhTdByIz5f"
      },
      "outputs": [],
      "source": [
        "# original author: tech-practice ;  original github repo: https://github.com/s9roll7/animatediff-cli-prompt-travel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7nBv_e9WRqrc",
        "outputId": "b7385d3d-5fdd-4291-9a3d-6e684598e96d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"ip\": \"34.83.121.56\",\n",
            "  \"hostname\": \"56.121.83.34.bc.googleusercontent.com\",\n",
            "  \"city\": \"The Dalles\",\n",
            "  \"region\": \"Oregon\",\n",
            "  \"country\": \"US\",\n",
            "  \"loc\": \"45.5946,-121.1787\",\n",
            "  \"org\": \"AS396982 Google LLC\",\n",
            "  \"postal\": \"97058\",\n",
            "  \"timezone\": \"America/Los_Angeles\",\n",
            "  \"readme\": \"https://ipinfo.io/missingauth\"\n",
            "}"
          ]
        }
      ],
      "source": [
        "# Use this to check the location of the server\n",
        "!curl ipinfo.io"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t8eFw7zfJmoc"
      },
      "outputs": [],
      "source": [
        "# it will ask you for permission to access the google drive folder,\n",
        "# please make sure that you are accessing the drive through the same account that you are running the colab notebook with.\n",
        "\n",
        "!apt-get -qq install aria2\n",
        "\n",
        "from google.colab import drive\n",
        "import os, shutil, gc, time\n",
        "import gdown\n",
        "base_path = \"/content/animatediff-cli-prompt-travel\"\n",
        "pwd = %pwd\n",
        "print(pwd)\n",
        "if pwd != base_path:\n",
        "  !git clone https://github.com/s9roll7/animatediff-cli-prompt-travel\n",
        "  %cd {base_path}\n",
        "\n",
        "  # Mount google drive\n",
        "  drive.mount(\"GoogleDrive\")\n",
        "  gd_path = \"GoogleDrive/MyDrive\"\n",
        "  gd_output_dir = gd_path + \"/AnimateDiffPromptTravel\"+\"/output\"\n",
        "\n",
        "  # create a folder called \"AnimateDiffPromptTravel\" under \"GoogleDrive/MyDrive\"\n",
        "  os.makedirs(gd_output_dir, exist_ok=True)\n",
        "\n",
        "  #Install all dependencies under the base path\n",
        "  !pip install torch==2.0.1+cu118 torchvision==0.15.2+cu118 torchaudio==2.0.2 --index-url https://download.pytorch.org/whl/cu118\n",
        "  !pip install .[dev]\n",
        "  !pip install xformers mediapipe\n",
        "  !pip install onnxruntime-gpu pandas\n",
        "  from IPython.display import clear_output\n",
        "  clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g_Z5Mzc_JmvR"
      },
      "outputs": [],
      "source": [
        "# AnimateDiff MotionModule download, you can customize this in the last code cell\n",
        "def dnld_mm(mm):\n",
        "  data_dir = \"data\"\n",
        "  motion_module = mm\n",
        "  motion_module_path = f\"models/motion-module/{motion_module}.ckpt\"\n",
        "  motion_module_file_path = os.path.join(data_dir, motion_module_path)\n",
        "  if not os.path.exists(motion_module_file_path):\n",
        "    url = f\"https://huggingface.co/guoyww/animatediff/resolve/main/{motion_module}.ckpt\"\n",
        "    !aria2c {url} -o {motion_module_file_path} #Download the MM model checkpoint file from the URL\n",
        "  return motion_module_path #Vikram 12/1/23"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s0XepFH4Jmx9"
      },
      "outputs": [],
      "source": [
        "# Standard Diffussion model download\n",
        "# feel free to experiment other models, you can customize this in the last code cell\n",
        "def dnld_sd(url, name):\n",
        "  data_dir = \"data\"\n",
        "  model_url = url\n",
        "  model_name = name\n",
        "#   model_path = f\"models/sd/{model_name}.safetensors\" #Vikram 12/1/23\n",
        "  model_path = f\"models/sd/{model_name}\" #Vikram 12/1/23\n",
        "  model_file_path = os.path.join(data_dir, model_path)\n",
        "  if not os.path.exists(model_file_path):\n",
        "    !aria2c {model_url} -o {model_file_path} #Download the MM model checkpoint file from the URL\n",
        "\n",
        "  return model_path #Vikram 12/1/23"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-DTDY1JltjJI"
      },
      "outputs": [],
      "source": [
        "# Colab free version has limited RAM. SO, delete the images from controlnet folder so that the program runs without interruptions.\n",
        "def cleanup(folder_path):\n",
        "  if len(os.listdir(folder_path)) > 1:\n",
        "    os.remove(f\"{folder_path}/0000.png\")\n",
        "    os.remove(f\"{folder_path}/0016.png\")\n",
        "    os.remove(f\"{folder_path}/0032.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WwTO7zsguBVp"
      },
      "outputs": [],
      "source": [
        "# take about 14-15 minutes depending on the diffussion model that you chose, and the total number of frames that are geenrated.\n",
        "def inference(config, W, H, L, C):\n",
        "  !animatediff generate -c {config} -W {W} -H {H} -L {L} -C {C}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8SzoIvKeJm5a"
      },
      "outputs": [],
      "source": [
        "# Copy generated contents to Google drive\n",
        "def cpy_to_drive():\n",
        "  output_dir = \"output\"\n",
        "  gc.collect()\n",
        "\n",
        "  def get_new_dir(parent_dir):\n",
        "    sub_dirs = []\n",
        "    for path in os.listdir(parent_dir):\n",
        "      dir_path = os.path.join(parent_dir, path)\n",
        "      if os.path.isdir(dir_path):\n",
        "        sub_dirs.append(dir_path)\n",
        "    # print(\"VIKRAM VIKRAM VIKRAM\", sub_dirs)\n",
        "    return max(sub_dirs, key = os.path.getmtime)\n",
        "\n",
        "  result_dir = get_new_dir(output_dir)\n",
        "  dest_dir = os.path.join(gd_output_dir, os.path.basename(result_dir))\n",
        "  shutil.copytree(result_dir, dest_dir, dirs_exist_ok = True) #Copy the file directory tree to the google drive folder\n",
        "  print(f\"ðŸŽ‰ The output files have been copied into {dest_dir}. (in your connected Google Drive) See you there! ðŸŽ‰\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eSgcWwQ1r9LD"
      },
      "outputs": [],
      "source": [
        "def json_modif(config, L, mmpath, sdpath): #Vikram 12/1/23\n",
        "\n",
        "  #BOC 11/28\n",
        "  !pip install google-generativeai\n",
        "  import google.generativeai as palm\n",
        "  palm.configure(api_key='')\n",
        "  #EOC 11/28\n",
        "\n",
        "  #------------------------------------------------\n",
        "  models = [m for m in palm.list_models() if 'generateText' in m.supported_generation_methods]\n",
        "\n",
        "  model = models[0].name\n",
        "\n",
        "  no_lines = \"5\" #@param {allow-input: true, type: \"string\"}\n",
        "  fps = 16 #@param {allow-input: true, type: \"integer\"}\n",
        "  if fps > L:\n",
        "    raise ValueError(\"The given FPS is more than the total number of frames generated. Please re-run the cell, and give proper inputs.\")\n",
        "\n",
        "\n",
        "  #Vikram 12/1/23\n",
        "  op_format = \"mp4\" #@param [\"mp4\", \"gif\", \"webm\"]\n",
        "\n",
        "  head_prompt = \"(standing,full_body), 5men on the left, 5men on the right, road in the middle with people, blue_sky, town\" #@param {allow-input: true, type: \"string\"}\n",
        "  prompt_travel = \"(standing,full_body), 5men_on_the_left, guns_in_hands, 5men_on_right, guns_in_hands, road_in_the_middle_with_people_walking, angry, tention, blue_sky, town\" #@param {allow-input: true, type: \"string\"}\n",
        "  tail_prompt = \"face, looking at the viewer, detailed background\" #@param {allow-input: true, type: \"string\"}\n",
        "  n_prompt = [\"worst quality\", \"low quality:1.4\", \"blurry faces\"] #@param {allow-input: true, type: \"raw\"}\n",
        "\n",
        "  prompt = f\"\"\"\n",
        "  You are an expert at text genetation.\n",
        "\n",
        "  expand the prompt into {no_lines} lines story should have the coherence from one line to the next line like a video\n",
        "\n",
        "  Prompt: {prompt_travel}\n",
        "\n",
        "  \"\"\"\n",
        "  #Generation of the prompt travel\n",
        "  completion = palm.generate_text(\n",
        "    model=model,\n",
        "    prompt=prompt,\n",
        "    temperature=0.1,\n",
        "    # The maximum length of the response\n",
        "    max_output_tokens=800,\n",
        "  )\n",
        "\n",
        "\n",
        "  #split the prompt travel into separate sentences\n",
        "\n",
        "  prompt_map = completion.result.split(\".\")\n",
        "\n",
        "  prompt_map1 = []\n",
        "  for i in range(len(prompt_map)):\n",
        "    if i%2 != 0:\n",
        "      prompt_map1.append(prompt_map[i])\n",
        "\n",
        "\n",
        "\n",
        "  #overwrite the existing data in the json file\n",
        "  import json\n",
        "  # Read the existing JSON file\n",
        "  with open(config, 'r') as json_file:\n",
        "      data = json.load(json_file)\n",
        "  i = 0\n",
        "\n",
        "  #path to the sd model\n",
        "  data[\"path\"] = sdpath #Vikram 12/1/23\n",
        "  #path to the mm model\n",
        "  data[\"motion_module\"] = mmpath #Vikram 12/1/23\n",
        "\n",
        "  #head prompt\n",
        "  data['head_prompt'] = head_prompt\n",
        "\n",
        "  #prompt travel\n",
        "  for line in prompt_map1:\n",
        "    pos = str(i)\n",
        "    data['prompt_map'][pos] = line\n",
        "    i+=fps\n",
        "\n",
        "  #tail prompt\n",
        "  data['tail_prompt'] = tail_prompt\n",
        "\n",
        "  #negative prompt\n",
        "  data['n_prompt'] = n_prompt\n",
        "\n",
        "  #-----------------------------------------------\n",
        "  #Output details\n",
        "  data['output']['format'] = op_format\n",
        "  data['output']['fps'] = fps\n",
        "\n",
        "  # Write the updated data back to the JSON file\n",
        "  with open(config, 'w') as json_file:\n",
        "      json.dump(data, json_file, indent=2)\n",
        "\n",
        "  return config, prompt_map1\n",
        "  #------------------------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EvDSGO9wJnA-"
      },
      "outputs": [],
      "source": [
        "# displaying generated prompt\n",
        "display_prompt = True #@param {type:\"boolean\"}\n",
        "generate_prompt = True #@param {type:\"boolean\"}\n",
        "\n",
        "# -- Parameters for the program to run --\n",
        "\n",
        "# Please make sure that you have inputs for the prompt to travel throughout the frames.\n",
        "# if you want to generate video with 128 frames with 8FPS, then write the prompt accordingly.\n",
        "# The guideline for the prompt can be seen directly in the original repo\n",
        "\n",
        "# Motion Module\n",
        "mm = \"mm_sd_v15_v2\" #@param {allow-input: true, type: \"string\"}\n",
        "\n",
        "# Standard Diffussion model\n",
        "url = \"https://civitai.com/api/download/models/102222\" #@param {allow-input: true, type: \"string\"}\n",
        "name = \"xxmix9realistic_v40.safetensors\" #@param {allow-input: true, type: \"string\"}\n",
        "\n",
        "# File path to fetch the prompt for the application\n",
        "config = \"GoogleDrive/MyDrive/AnimateDiffPrompts/prompt_dummy.json\"#@param {allow-input: true, type: \"string\"}\n",
        "\n",
        "# Width of the frame\n",
        "W = 80 #@param {allow-input: true, type: \"number\"}\n",
        "# Height of the frame\n",
        "H = 80 #@param {allow-input: true, type: \"number\"}\n",
        "# Total number of frames\n",
        "L = 80 #@param {allow-input: true, type: \"number\"}\n",
        "\n",
        "C = 16 #@param {allow-input: true, type: \"number\"}\n",
        "\n",
        "\n",
        "mmpath = dnld_mm(mm) #Vikram 12/1/23\n",
        "sdpath = dnld_sd(url, name) #Vikram 12/1/23\n",
        "\n",
        "if generate_prompt:\n",
        "    # editing the config file (prompt file)\n",
        "    config, prompt_map1 = json_modif(config, L, mmpath, sdpath) #Vikram 12/1/23\n",
        "\n",
        "    # Check the value of the checkbox\n",
        "    if display_prompt:\n",
        "        # from ipywidgets import Output\n",
        "        from IPython.display import clear_output\n",
        "        clear_output()\n",
        "        print(prompt_map1)\n",
        "        # Add actions to perform when the checkbox is checked\n",
        "    else:\n",
        "        print(\"Display checkbox is unchecked.\")\n",
        "        # Add actions to perform when the checkbox is unchecked\n",
        "\n",
        "\n",
        "# Clean up of the control net reference image folder\n",
        "folder_path = \"data/controlnet_image/test/controlnet_softedge\"\n",
        "cleanup(folder_path)\n",
        "folder_path = \"data/controlnet_image/test/controlnet_openpose\"\n",
        "cleanup(folder_path)\n",
        "\n",
        "inference(config, W, H, L, C)\n",
        "\n",
        "cpy_to_drive()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
