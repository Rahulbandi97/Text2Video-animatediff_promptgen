# Text2Video-animatediff_promptgen
A Video Generator based on the given Text

The aim of this Text-to-Video project is to generate a video/moving picture from the prompt the user gives it, based on some parameters.

The project is based on the Animatediff CLI project (credited below), with a generative prompt patch that we have added to it.  

The project is built as a google Colab notebook at it's core. We recommend users use Colab for working with the program.

(This project is under further development)
  
### How to run it (prerequisites)

-------
 

The project is written in a Colab notebook, and we recommend the users use it on Colab itself, users don't need to install anything separately if they want to run the project as it is. The dependency installations are already present in the initial cells of the notebook.

There are some things the user needs to complete before running the program.

The users should create 2 folders in their google drive for the program to read the input and write the output. the details are mentioned below.

1. users should upload the input config script to the google drive to folder (ex: AnimateDiffPrompts)
2. There is a folder that gets created automatically,
	1. AnimateDiffPromptTravel (output folder) (automatically created)

  
Please make sure that the folder path to the input folder/file is correct before running the program.

API key generation: User needs to generate API keys for using prompt generation. The project makes use of PaLM API to generate the prompt based on the user's concise input. So, the user needs to generate the API key for PaLM in order to use prompt generation.

The API key can be generated by the user in Google's Makersuite website.

**Also, please make a note that the google account that is used to run the Colab file is the same account whose drive is mounted to the runtime.**

In the AnimateDiffPromptTravel Folder, try to create two folders with names static and templates where in static we store the .css files, .js files and in templates we store the .html files. This setup is useful at the time of retrieving in Flask app request call

Authentication Token Generation : Please generate the Authentication token from the ngrok site and save it, so that we need to use this token at the time of ngrok authentication

### How to use it (guidelines)

----


There are some important things that the user should look over while running the project.
1. Please make sure that the Colab runtime is in the right country for the PaLM to work. the list of allowed countries is given in the notebook along with guidelines.
2. the google drive mounting permission.
3. The project reads the input and writes the output to a google drive folder(as mentioned above). The user should be giving the program the permission to mount the drive folders to the current runtime.
4. The name of the stable diffusion model should match the URL that is given to download the model. Any mismatch could be fatal to the program.
5. the config file is the input file that is given by the user to the program. This file contains parameters and the prompt that the program functions with. the explanation of the config file is given in another document that is named "config_explanation".
6. Please make sure that the total number of frames (L) is more than the frames per second (fps) parameter.
7. The names of the SD(stable diffusion) models should be with the file extension to allow more freedom to the user. The user can use any kind of SD model. For instance, the user could use ".safetensors" file or ".tensorart" file.
8. After running all the cells and in the last cell we have the flask app and ngrok configuration, where every time when that cell is being run, a new dynamic host url will be generated for the ngrok.
9. we use the above host url to redirect to UI, which takes the inputs from the user and after clicking on the Generate Video button, the video generation process begins and after completion the video, the frames and video will be stored in the Google drive in the output folder under a separate folder

There are several parameters in the program that variably effect the execution time for the program.

1. Frame dimensions: dimensions of the frame influence the execution time a lot as it is a generative task. the bigger the dimension, longer the runtime.
2. Complexity of the prompt: more complex (more happening) the prompt is, longer the runtime.
3. SD model efficiency: There are a lot of SD models on the internet, and based on their training and style of generation, some may take more time than when compared to other simple ones.
4. Video duration: video duration is directly proportional to the execution time of the program.

 There is a section in the program where the controlnet images are getting removed from the runtime to save space(since we are running a colab instance). Users are free to comment that piece of code and experiment with the controlnet parameters in their implementations.
  
  Some of the SD model names and URLs:
  1. Lyriel -> https://civitai.com/api/download/models/72396
  2. ToonYou -> https://civitai.com/api/download/models/78775
  3. RCNZ Cartoon 3d -> https://civitai.com/api/download/models/71009
  4. majicMIX realistic -> https://civitai.com/api/download/models/79068
  5. Realistic Vision V6.0 B1 -> https://civitai.com/api/download/models/29460
  6. xxmix9realistic_v40 -> https://civitai.com/api/download/models/102222
### credits

- AnimateDIffCLI

    - author: neggles ;  github repo: [neggles/animatediff-cli: a CLI utility/library for AnimateDiff stable diffusion generation (github.com)](https://github.com/neggles/animatediff-cli)

- AnimateDiffCLI-Prompt-Travel

    - author: s9roll7; github repo: [s9roll7/animatediff-cli-prompt-travel: animatediff prompt travel (github.com)](https://github.com/s9roll7/animatediff-cli-prompt-travel)

 - AnimateDiff

     - author: ; github repo: [guoyww/AnimateDiff: Official implementation of AnimateDiff. (github.com)](https://github.com/guoyww/AnimateDiff)

 Guidance videos on YT:

 - [Google Colab notebook for AnimateDiff-cli-prompt-travel for everyone! Click buttons to get gif! - YouTube](https://www.youtube.com/watch?v=hTWU3JRB-N0&ab_channel=Tech-Practice)

 - [Text to video - Windows tutorial for AnimateDiff-cli-prompt-travel (also Linux) #stablediffusion - YouTube](https://www.youtube.com/watch?v=PkAVpvgeRyA&ab_channel=Tech-Practice)